{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição de propriedades moleculares com aprendizado de máquina\n",
    "\n",
    "O projeto busca aplicar técnicas de aprendizado de máquina para otimização de processos laboratoriais. Para isso, contamos com o carregamento de dados experimentais do dataset [QM9](http://quantum-machine.org/datasets/), o qual disponibiliza a informação da energia **homo - lumo**, o **momento de dipolo** e o número de átomos de mais de 130000 moléculas orgânicas, indexadas pelos respectivos SMILES, as quais são formadas pelos átomos de carbono, oxigênio, fluor e nitrogênio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library import\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns \n",
    "from rdkit import Chem\n",
    "\n",
    "# machine learning library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#local module import\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/edmurcn/Documentos/MeusProjetos/Predicao_Molecular\")) \n",
    "from src.modeling_utils import DataIngestion, DataIngestion_pipe\n",
    "from src.model_train2 import evaluate_models_cv_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de moléculas: 133885\n",
      "--------------------------------------------------\n",
      "Colunas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>n_atoms</th>\n",
       "      <th>homo_lumo_nm</th>\n",
       "      <th>dipole_moment_debye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [smiles, n_atoms, homo_lumo_nm, dipole_moment_debye]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data input\n",
    "\n",
    "df_mol = pd.read_csv(\"/home/edmurcn/Documentos/MeusProjetos/Predicao_Molecular/data/origin_dataset.csv\", header=0)\n",
    "\n",
    "print(\"Número de moléculas:\", df_mol.shape[0])\n",
    "print(50*\"-\")\n",
    "print(\"Colunas:\")\n",
    "df_mol.head(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smiles                 0\n",
       "n_atoms                0\n",
       "homo_lumo_nm           0\n",
       "dipole_moment_debye    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there is NaN values\n",
    "\n",
    "df_mol.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tratamento e ingestão de dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa aplicamos uma linha de processamento contida na classe **DataIngestion()** para gerar um novo conjunto de dados, os processos são apresentados abaixo:\n",
    "\n",
    "- **drop_duplicated()** : Método utilizado para retirar moléculas duplicadas do conjunto de dados original. De acordo com as referências do projeto, existe a possibilidade de a mesma molécula ser escrita com SMILES diferentes, como 'C=CCC' e 'CCC=C', apesar de representarem a mesma estrutura, são escritos de maneira diferente devido a simetria.\n",
    "\n",
    "- **get_features()** : Método utilizado para gerar características das moléculas e adicionar ao conjunto original. As novas características serão geradas através do resultado de todos os descritores presentes na biblioteca RDKit (biblioteca voltada a química computacional).\n",
    "\n",
    "- **get_best_features()**: Método que seleciona as características com melhor perfil para serem usadas em dados de predição. Buscamos selecionar as features de acordo com o valor de correlação e da variância, dado que colunas com grandes correlações ou pequena variância foram excluídas.\n",
    "\n",
    "Por fim, os métodos podem ser executados separadamente ou, ao utilizar a classe **DataIngestion_pipe()**, temos a execução em sequência de todos os métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is commented because the data was created and saved in the path, so just run it to create new data\n",
    "\n",
    "# data_ingestion = DataIngestion_pipe()\n",
    "# data_ingestion.fit_transform(X=df_mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de moléculas: 133798\n",
      "--------------------------------------------------\n",
      "Novas colunas: 141\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>n_atoms</th>\n",
       "      <th>homo_lumo_nm</th>\n",
       "      <th>dipole_moment_debye</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>MaxPartialCharge</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_para_hydroxylation</th>\n",
       "      <th>fr_phenol</th>\n",
       "      <th>fr_piperdine</th>\n",
       "      <th>fr_piperzine</th>\n",
       "      <th>fr_priamide</th>\n",
       "      <th>fr_pyridine</th>\n",
       "      <th>fr_quatN</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [smiles, n_atoms, homo_lumo_nm, dipole_moment_debye, MaxAbsEStateIndex, MinAbsEStateIndex, MinEStateIndex, qed, MolWt, MaxPartialCharge, MinPartialCharge, FpDensityMorgan1, BCUT2D_MWHI, BCUT2D_MWLOW, BCUT2D_CHGHI, BCUT2D_CHGLO, BCUT2D_LOGPLOW, BCUT2D_MRHI, BCUT2D_MRLOW, AvgIpc, BalabanJ, BertzCT, Chi0, Chi0v, Chi1v, HallKierAlpha, Ipc, Kappa1, Kappa2, Kappa3, PEOE_VSA1, PEOE_VSA10, PEOE_VSA11, PEOE_VSA12, PEOE_VSA13, PEOE_VSA14, PEOE_VSA2, PEOE_VSA3, PEOE_VSA4, PEOE_VSA5, PEOE_VSA6, PEOE_VSA7, PEOE_VSA8, PEOE_VSA9, SMR_VSA1, SMR_VSA10, SMR_VSA2, SMR_VSA3, SMR_VSA4, SMR_VSA5, SMR_VSA6, SMR_VSA7, SMR_VSA9, SlogP_VSA1, SlogP_VSA10, SlogP_VSA11, SlogP_VSA2, SlogP_VSA3, SlogP_VSA4, SlogP_VSA5, SlogP_VSA7, SlogP_VSA8, TPSA, EState_VSA1, EState_VSA10, EState_VSA2, EState_VSA3, EState_VSA4, EState_VSA5, EState_VSA6, EState_VSA7, EState_VSA8, EState_VSA9, VSA_EState3, VSA_EState4, VSA_EState5, VSA_EState6, VSA_EState7, VSA_EState8, VSA_EState9, NHOHCount, NumAliphaticCarbocycles, NumAliphaticHeterocycles, NumAliphaticRings, NumAromaticCarbocycles, NumAromaticHeterocycles, NumRotatableBonds, MolLogP, MolMR, fr_Al_COO, fr_Al_OH, fr_Al_OH_noTert, fr_ArN, fr_Ar_COO, fr_Ar_N, fr_Ar_NH, fr_Ar_OH, fr_HOCCN, fr_Imine, fr_NH0, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 141 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mol_new = pd.read_csv(\"/home/edmurcn/Documentos/MeusProjetos/Predicao_Molecular/data/data_best_features.csv\", header=0)\n",
    "print(\"Número de moléculas:\", df_mol_new.shape[0])\n",
    "print(50*\"-\")\n",
    "print(\"Novas colunas:\", df_mol_new.shape[1])\n",
    "df_mol_new.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dicionário dos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and dropping homo_lumo columns - because is a highly correlated with dipole columns and its a possible target in the others preditions\n",
    "# Save and dropping smiles and dipole_moment_debye columns\n",
    "\n",
    "homo_lumo = df_mol_new[\"homo_lumo_nm\"]\n",
    "\n",
    "smile_and_target = df_mol_new[[\"smiles\", \"dipole_moment_debye\"]]\n",
    "\n",
    "df_mol_new = df_mol_new.drop([\"homo_lumo_nm\", \"smiles\", \"dipole_moment_debye\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Redução de dimensionalidade**\n",
    "\n",
    "Nesta etapa testamos alguns métodos para reduzir ainda mais a dimensão dos dados. Serão aplicados métodos como **PCA()**, **LDA()**... em uma amostra aleatória, contendo 10000 instẫncias dos dados originais.\n",
    "\n",
    "- **PCA** (*Principal Components Analysis*): O componente principal é um vetor unitário compostos por contribuições de cada feature do dataset, com esses vetores é possível formar hiperplanos e assim realizar a projeção dos dados para obter o máximo de variância explicada (informação) no mínimo de dimensões possíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107038,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the train and test datasets and standardize scale\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_mol_new, smile_and_target[\"dipole_moment_debye\"], test_size=0.2, random_state=0)\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "x_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de componentes principais: 70\n",
      "--------------------------------------------------\n",
      "Contribuição em taxa de variância explicada de cada componente:\n",
      "--------------------------------------------------\n",
      "[0.15597672 0.06137889 0.05156915 0.04584766 0.03750378 0.03442346\n",
      " 0.03073575 0.02629401 0.02038951 0.01985551 0.01950092 0.01704463\n",
      " 0.01662826 0.01540467 0.01468783 0.01371115 0.01289675 0.01281101\n",
      " 0.01188442 0.0113059  0.01092915 0.01062289 0.01036587 0.00989117\n",
      " 0.00951487 0.00924796 0.00867506 0.00848655 0.00833669 0.00812761\n",
      " 0.0080102  0.00786781 0.00764632 0.00750701 0.00740467 0.00734956\n",
      " 0.00726372 0.00726053 0.00723058 0.00720648 0.00715004 0.00702522\n",
      " 0.00688086 0.00681215 0.00663761 0.00657208 0.00628369 0.00623896\n",
      " 0.00595841 0.00585417 0.00576835 0.00568229 0.00545408 0.00531152\n",
      " 0.00502969 0.00498392 0.00494856 0.00486765 0.00469256 0.00447829\n",
      " 0.00409456 0.00390719 0.00380737 0.00378078 0.00371903 0.00342495\n",
      " 0.00325135 0.0031904  0.0031396  0.00294138]\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA methods to explain more than 95% of data variance\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "x_train_reduced = pca.fit_transform(x_train)\n",
    "x_test_reduced = pca.transform(x_test)\n",
    "\n",
    "print(\"Número de componentes principais:\", x_train_reduced.shape[1])\n",
    "print(50*\"-\")\n",
    "print(\"Contribuição em taxa de variância explicada de cada componente:\")\n",
    "print(50*\"-\")\n",
    "print(pca.explained_variance_ratio_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que o método de PCA desempenha muito bem a redução de dimensionalidade, porém, dentre os componentes principais obtidos, cada um contribui com uma baixa taxa de variância explicada, evidenciando que não uma coluna que diferencie com eficácia as amostras. Logo, deve-se avaliar no processo de treinamento se o tempo ganho com a redução de dimensionalidade compensa a informação perdida ao realizar o método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar a exploração dos dados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
